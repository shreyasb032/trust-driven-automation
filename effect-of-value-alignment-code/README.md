# Code for the paper titled 'Effect of Value Alignment on Trust: A Simulation Study'

Runs the Bayesian IRL algorithm on the bounded rationality disuse model for the  human

Independently varies the health reward weight of the robot and the human and saves the trust data

Plots the end-of-mission trust as a function of the reward weights of the human and the robot. 4 regions can be observed based on the value alignment

Varies the general level of threat and saves and plots the end-of-mission trust as a function of this threat level for different cases of value alignment (different regions)

