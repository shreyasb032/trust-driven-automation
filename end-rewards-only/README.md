# Main idea here is that the robot will try to optimize the ending state of the human

The robot will only get rewards at the final stage, depending on the health of the soldier and the time taken in the mission.

The human will observe immediate rewards and vary trust accordingly.

It will be interesting to see how value alignment/misalignment affects trust in this case. 
